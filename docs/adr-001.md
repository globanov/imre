# ADR-001: Synchronous Event Processing for Workload Aggregation

## Status
Accepted (MVP)

## Context
We need to update weekly workload totals when a shift is created.  
Initial designs considered an async worker with Redis, but we opted for simplicity.

## Decision
Use **synchronous event processing within the Django monolith**:
- No message broker (Redis/Kafka)
- No separate worker process or service
- Event handler (`handle_shift_created`) called directly from the API view
- Full operation is atomic (DB transaction includes aggregate update)

## Rationale
- **MVP focus**: deliver core functionality fast, with minimal moving parts
- **Operational simplicity**: no queues, no dead-letter topics, no retry logic
- **Consistency**: aggregates are always up-to-date after API response
- **Debuggability**: single call stack, easy logging and testing
- **Future-proof**: clean architecture allows extracting worker later if needed

## Consequences
- HTTP request latency includes aggregation time (~1–5 ms) — acceptable for MVP
- No built-in retry for failed updates (but failures are rare in sync flow)
- Scaling to high throughput will require async worker — low effort due to decoupled design

## Alignment
- ✅ Matches code: `publish(event)` → direct call to `handle_shift_created`
- ✅ Matches README: "synchronous processing, no message broker"
- ✅ Matches deployment: single Render service, no Redis
